# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_leaner.ipynb (unless otherwise specified).

__all__ = ['get_generator_learner', 'get_critic_learner']

# Cell
from fastai2.basics import *
from fastai2.text.all import *
from fastai2.callback.all import *

from .loss import *

# Cell
def get_generator_learner(dls, generator):
    return Learner(dls, generator, loss_func=FeatureLoss('cuda'), opt_func=Adam).to_fp16()

# Internal Cell
def displayable_caption(caption):
    new_cap = []
    for i, w in enumerate(caption.split()):
        i+=1
        if i>11: break
        new_cap.append(w)
        if i%6==0: new_cap.append('\n')
    return ' '.join(new_cap)
@typedispatch
def show_results(x:TensorText, y:TensorImage, samples, outs, ctxs=None, max_n=10, **kwargs):
    n = min(len(samples), max_n)
    ncols = 4
    nrows = math.ceil((2*n)/ncols)
    figsize = (ncols*4, nrows*4)
    if ctxs is None:
        _, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
        ctxs = ax.flatten()
    for i in range(n):
        caption, targ_img = samples[i]
        pred_img = outs[i][0]
        targ_img.show(ctxs[i*2])
        pred_img.show(ctxs[i*2+1])
        ctxs[i*2].text(0, -1.5, displayable_caption(caption))

# Cell
def get_critic_learner(dls, critic):
    return Learner(dls, critic, loss_func=BCEWithLogitsLossFlat(), metrics=[accuracy], opt_func=Adam).to_fp16()