{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai2_utils.pytorch.model import set_requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FeatureLoss():\n",
    "    def __init__(self, device, layer_wgts=[20, 70, 10]):\n",
    "        super().__init__()\n",
    "        self.wgts = layer_wgts\n",
    "        self.m_feat = torchvision.models.vgg16_bn(True).features.to(device).eval()\n",
    "        set_requires_grad([self.m_feat], False)\n",
    "        l_feat = [l for l in self.m_feat.children() if isinstance(l, nn.MaxPool2d)][2:5]\n",
    "        self.hooks = hook_outputs(l_feat, detach=False)\n",
    "\n",
    "    def make_features(self, x):\n",
    "        ''' return list of output from 3 layers of vgg16 '''\n",
    "        self.m_feat(x)\n",
    "        return self.hooks.stored\n",
    "\n",
    "    def __call__(self, inp, targ):\n",
    "        inp = inp.float()\n",
    "        targ = targ.float()\n",
    "        inp_feats = self.make_features(inp)\n",
    "        targ_feats = self.make_features(targ)\n",
    "\n",
    "        # feat_losses = [mae of raw pixels, mae of 1st layer, mae of 2nd layer, mae of 3rd layer]\n",
    "        feat_losses = [F.l1_loss(inp, targ)]\n",
    "        feat_losses += [\n",
    "            F.l1_loss(inp_feat, targ_feat) * w\n",
    "            for inp_feat, targ_feat, w in zip(inp_feats, targ_feats, self.wgts)\n",
    "        ]\n",
    "        return torch.stack(feat_losses).mean(dim=0)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = FeatureLoss('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.ones(16, 3, 64, 64, requires_grad=True)\n",
    "targ = torch.ones(16, 3, 64, 64)\n",
    "l = loss(inp, targ)\n",
    "test_eq(l, 0)\n",
    "test_eq(l.requires_grad, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.zeros(16, 3, 64, 64, requires_grad=True)\n",
    "targ = torch.ones(16, 3, 64, 64)\n",
    "l = loss(inp, targ)\n",
    "test_close(l, 1, eps=1)\n",
    "test_eq(l.requires_grad, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_eda[script].ipynb.\n",
      "Converted 01_gen_coco_tiny_data[script].ipynb.\n",
      "Converted 02_data_coco.ipynb.\n",
      "Converted 03_model.ipynb.\n",
      "Converted 04_loss.ipynb.\n",
      "Converted 90a_fulltest_train_lm.ipynb.\n",
      "Converted 95a_train_lm[script].ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
